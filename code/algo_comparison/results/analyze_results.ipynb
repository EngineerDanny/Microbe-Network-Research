{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "import plotnine.options as p9options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_results_dir = \"/projects/genomic-ml/da2343/ml_project_1/algo_comparison/results\"\n",
    "\n",
    "# date_time = \"2023-03-06_17:34\"\n",
    "# date_time = \"2023-03-22_17:46\"\n",
    "# date_time = \"2023-03-22_18:45\"\n",
    "# date_time = \"2023-03-22_19:15\"\n",
    "# date_time = \"2023-04-03_18:15\"\n",
    "# date_time = \"2023-04-03_18:31\"\n",
    "date_time = \"2023-03-22_18:12\"\n",
    "date_time = \"2023-03-22_19:01\"\n",
    "date_time = \"2023-04-10_11:18\"\n",
    "date_time = \"2023-04-10_12:28\"\n",
    "\n",
    "# date_time = \"2023-04-10_17:47\"\n",
    "date_time = \"2023-04-10_15:31\"\n",
    "date_time = \"2023-05-29_12:40\"\n",
    "date_time = \"2023-06-21_17:26\"\n",
    "date_time = \"2023-06-21_19:01\"\n",
    "date_time = \"2023-06-28_13:01\"\n",
    "# date_time = \"2023-07-19_20:27\"\n",
    "date_time = \"2023-07-20_16:36\"\n",
    "\n",
    "# NECROMASS DF\n",
    "# date_time = \"2023-07-20_16:44\"\n",
    "# date_time = \"2023-08-03_18:13\"\n",
    "date_time = \"2023-08-18_14:28\"\n",
    "date_time = \"2023-08-18_14:28\"\n",
    "date_time = \"2023-09-15_18:01\"\n",
    "# date_time = \"2023-09-15_20:03\"\n",
    "# date_time = \"2023-10-02_08:20\"\n",
    "# date_time = \"2023-10-02_08:33\"\n",
    "# date_time = \"2023-10-02_09:44\"\n",
    "date_time = \"2023-10-02_11:20\"\n",
    "date_time = \"2023-10-02_14:35\"\n",
    "date_time = \"2023-10-02_18:42\"\n",
    "date_time = \"2023-10-10_09:23\"\n",
    "date_time = \"2023-10-10_10:37\"\n",
    "date_time = \"2023-10-12_22:17\"\n",
    "date_time = \"2024-02-05_08:41\"\n",
    "\n",
    "\n",
    "error_df = pd.read_csv(f\"{root_results_dir}/{date_time}_results.csv\")\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = error_df.groupby(['Dataset', 'Algorithm', '# of Total Samples']).mean().reset_index()\n",
    "df_std = error_df.groupby(['Dataset', 'Algorithm', '# of Total Samples']).std().reset_index()\n",
    "df_mean = df_mean.drop(columns=['FoldID', 'Index of Subsample', 'Index of Predicted Column'])\n",
    "df_std = df_std.rename(columns={\"Mean Squared Error\": \"std\"})\n",
    "df_std = df_std[\"std\"] * 0.1\n",
    "df = pd.concat([df_mean, df_std], axis=1)\n",
    "df[\"ymin\"] = df[\"Mean Squared Error\"] - df[\"std\"]\n",
    "df[\"ymax\"] = df[\"Mean Squared Error\"] + df[\"std\"]\n",
    "df\n",
    "\n",
    "# remove \"Dec22\" from the dataset names\n",
    "df[\"Dataset\"] = df[\"Dataset\"].str.replace(\"Dec22_\", \"\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import plotnine.options as p9options\n",
    "p9options.figure_size = (15, 2)\n",
    "\n",
    "colors = [\"orange\", \"#67001f\", \"#053061\", \"blue\", \"red\"]\n",
    "p = ggplot(df)\n",
    "p = p + aes(x=\"# of Total Samples\", y=\"Mean Squared Error\", ymin=\"ymin\", ymax=\"ymax\", fill=\"Algorithm\")\n",
    "p = p + facet_grid(\"~Dataset\", scales=\"free\")\n",
    "p = p + geom_line(aes(color=\"Algorithm\"))\n",
    "p = p + geom_ribbon(alpha=0.3)\n",
    "p = p + scale_fill_manual(breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors)\n",
    "p = p + scale_color_manual(breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Get unique values as list from column name `Dataset`\n",
    "dataset_list = error_df[\"Dataset\"].unique().tolist()\n",
    "colors = [\"orange\", \"#67001f\", \"#053061\", \"blue\", \"red\"]\n",
    "test_error_df_list = []\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    sub_dataset_df = error_df[error_df[\"Dataset\"] == dataset]\n",
    "    n_samples_list = sub_dataset_df[\"# of Total Samples\"].unique().tolist()\n",
    "\n",
    "    for n_sample in n_samples_list:\n",
    "        filtered_csv = sub_dataset_df[sub_dataset_df[\"# of Total Samples\"] == n_sample]\n",
    "        algo_list = filtered_csv[\"Algorithm\"].unique().tolist()\n",
    "\n",
    "        for algorithm in algo_list:\n",
    "            sub_filtered_csv = filtered_csv[filtered_csv[\"Algorithm\"] == algorithm]\n",
    "            # Get new dataframe with only the dataset and n_sample\n",
    "            mean_mse = sub_filtered_csv[\"Mean Squared Error\"].mean()\n",
    "            std_mse = sub_filtered_csv[\"Mean Squared Error\"].std() * 0.1\n",
    "            # std_mse = sub_filtered_csv['Mean Squared Error'].std() * 0.1\n",
    "            mse_min = mean_mse - std_mse\n",
    "            mse_max = mean_mse + std_mse\n",
    "\n",
    "            test_error_dict = {\n",
    "                \"# of Total Samples\": n_sample,\n",
    "                \"Mean Squared Error\": mean_mse,\n",
    "                \"ymin\": mse_min,\n",
    "                \"ymax\": mse_max,\n",
    "                \"Dataset\": dataset,\n",
    "                \"Algorithm\": algorithm,\n",
    "            }\n",
    "            test_error_df_list.append(pd.DataFrame(test_error_dict, index=[0]))\n",
    "my_combined_results_df = pd.concat(test_error_df_list).reset_index()\n",
    "if categories is not None:\n",
    "    my_combined_results_df[\"Dataset\"] = pd.Categorical(\n",
    "        my_combined_results_df[\"Dataset\"],\n",
    "        categories=categories,\n",
    "        ordered=True,\n",
    "    )\n",
    "\n",
    "import plotnine.options as p9options\n",
    "p9options.figure_size = (10, 5)\n",
    "\n",
    "gg = (\n",
    "    p9.ggplot(my_combined_results_df)\n",
    "    + p9.aes(\n",
    "        x=\"# of Total Samples\",\n",
    "        y=\"Mean Squared Error\",\n",
    "        ymin=\"ymin\",\n",
    "        ymax=\"ymax\",\n",
    "        fill=\"Algorithm\",\n",
    "    )\n",
    "    + p9.facet_wrap(\"~Dataset\", scales=\"free\")\n",
    "    + p9.geom_line(p9.aes(color=\"Algorithm\"))\n",
    "    + p9.geom_ribbon(alpha=0.3)\n",
    "    + p9.scale_fill_manual(\n",
    "        breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors\n",
    "    )\n",
    "    + p9.scale_color_manual(\n",
    "        breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors\n",
    "    )\n",
    "    + p9.xlab(\"# of Total Samples\")\n",
    ")\n",
    "# show the plot\n",
    "print(gg)\n",
    "# TODO: Uncomment to save the plot\n",
    "# gg.save(f\"{name}.png\", dpi=700)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_graph(error_df, categories=None, name=\"test_error_graph\"):\n",
    "    # Get unique values as list from column name `Dataset`\n",
    "    dataset_list = error_df[\"Dataset\"].unique().tolist()\n",
    "    # colors = [\"#000080\", \"#FF8000\", \"#800080\", \"#8B0000\", \"#D3D3D3\"]\n",
    "    colors = [\"orange\", \"#67001f\", \"#053061\", \"blue\", \"red\"]\n",
    "\n",
    "    test_error_df_list = []\n",
    "\n",
    "    for dataset in dataset_list:\n",
    "        # remove multi\n",
    "        # Get new dataframe with only the dataset\n",
    "        sub_dataset_df = error_df[error_df[\"Dataset\"] == dataset]\n",
    "        n_samples_list = sub_dataset_df[\"# of Total Samples\"].unique().tolist()\n",
    "\n",
    "        for n_sample in n_samples_list:\n",
    "            filtered_csv = sub_dataset_df[\n",
    "                sub_dataset_df[\"# of Total Samples\"] == n_sample\n",
    "            ]\n",
    "            algo_list = filtered_csv[\"Algorithm\"].unique().tolist()\n",
    "\n",
    "            for algorithm in algo_list:\n",
    "                sub_filtered_csv = filtered_csv[filtered_csv[\"Algorithm\"] == algorithm]\n",
    "                # Get new dataframe with only the dataset and n_sample\n",
    "                mean_mse = sub_filtered_csv[\"Mean Squared Error\"].mean()\n",
    "                std_mse = sub_filtered_csv[\"Mean Squared Error\"].std() * 0.1\n",
    "                # std_mse = sub_filtered_csv['Mean Squared Error'].std() * 0.1\n",
    "                mse_min = mean_mse - std_mse\n",
    "                mse_max = mean_mse + std_mse\n",
    "\n",
    "                test_error_dict = {\n",
    "                    \"# of Total Samples\": n_sample,\n",
    "                    \"Mean Squared Error\": mean_mse,\n",
    "                    \"ymin\": mse_min,\n",
    "                    \"ymax\": mse_max,\n",
    "                    \"Dataset\": dataset,\n",
    "                    \"Algorithm\": algorithm,\n",
    "                }\n",
    "                test_error_df_list.append(pd.DataFrame(test_error_dict, index=[0]))\n",
    "    my_combined_results_df = pd.concat(test_error_df_list).reset_index()\n",
    "    if categories is not None:\n",
    "        my_combined_results_df[\"Dataset\"] = pd.Categorical(\n",
    "            my_combined_results_df[\"Dataset\"],\n",
    "            categories=categories,\n",
    "            ordered=True,\n",
    "        )\n",
    "\n",
    "    import plotnine.options as p9options\n",
    "    p9options.figure_size = (10, 5)\n",
    "    \n",
    "    gg = (\n",
    "        p9.ggplot(my_combined_results_df)\n",
    "        + p9.aes(\n",
    "            x=\"# of Total Samples\",\n",
    "            y=\"Mean Squared Error\",\n",
    "            ymin=\"ymin\",\n",
    "            ymax=\"ymax\",\n",
    "            fill=\"Algorithm\",\n",
    "        )\n",
    "        + p9.facet_wrap(\"~Dataset\", scales=\"free\")\n",
    "        + p9.geom_line(p9.aes(color=\"Algorithm\"))\n",
    "        + p9.geom_ribbon(alpha=0.3)\n",
    "        + p9.scale_fill_manual(\n",
    "            breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors\n",
    "        )\n",
    "        + p9.scale_color_manual(\n",
    "            breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors\n",
    "        )\n",
    "        + p9.xlab(\"# of Total Samples\")\n",
    "    )\n",
    "    # show the plot\n",
    "    print(gg)\n",
    "    # TODO: Uncomment to save the plot\n",
    "    # gg.save(f\"{name}.png\", dpi=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_error_df(error_df):\n",
    "    dataset_list = error_df[\"Dataset\"].unique().tolist()\n",
    "\n",
    "    for dataset in dataset_list:\n",
    "        test_error_df_list = []\n",
    "        # Get new dataframe with only the dataset\n",
    "        sub_dataset_df = error_df[error_df[\"Dataset\"] == dataset]\n",
    "        n_samples_list = sub_dataset_df[\"# of Total Samples\"].unique().tolist()\n",
    "\n",
    "        for n_sample in n_samples_list:\n",
    "            filtered_csv = sub_dataset_df[\n",
    "                sub_dataset_df[\"# of Total Samples\"] == n_sample\n",
    "            ]\n",
    "            algo_list = filtered_csv[\"Algorithm\"].unique().tolist()\n",
    "\n",
    "            for algorithm in algo_list:\n",
    "                sub_filtered_csv = filtered_csv[filtered_csv[\"Algorithm\"] == algorithm]\n",
    "                # Get new dataframe with only the dataset and n_sample\n",
    "                mean_mse = sub_filtered_csv[\"Mean Squared Error\"].mean()\n",
    "                std_mse = sub_filtered_csv[\"Mean Squared Error\"].std() * 0.02\n",
    "                # std_mse = sub_filtered_csv['Mean Squared Error'].std() * 0.01\n",
    "                mse_min = mean_mse - std_mse\n",
    "                mse_max = mean_mse + std_mse\n",
    "\n",
    "                test_error_dict = {\n",
    "                    \"# of Total Samples\": n_sample,\n",
    "                    \"Mean Squared Error\": mean_mse,\n",
    "                    \"ymin\": mse_min,\n",
    "                    \"ymax\": mse_max,\n",
    "                    \"Dataset\": dataset,\n",
    "                    \"Algorithm\": algorithm,\n",
    "                }\n",
    "                test_error_df_list.append(pd.DataFrame(test_error_dict, index=[0]))\n",
    "        my_combined_results_df = pd.concat(test_error_df_list).reset_index()\n",
    "    return my_combined_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sum_of_errors(bact_plus_fungi_df, bact_fungi_combined_df, name = None):\n",
    "    test_error_df_list = []\n",
    "    n_samples_list = (\n",
    "        bact_fungi_combined_df[\"# of Total Samples\"].unique().tolist()\n",
    "    )\n",
    "    for n_sample in n_samples_list:\n",
    "        filtered_bact_plus_fungi_df = bact_plus_fungi_df[\n",
    "            bact_plus_fungi_df[\"# of Total Samples\"] == n_sample\n",
    "        ]\n",
    "        \n",
    "        filtered_bact_fungi_combined_df = (\n",
    "            bact_fungi_combined_df[\n",
    "                bact_fungi_combined_df[\"# of Total Samples\"] == n_sample\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        custom_bact_fungi_sum_mse = filtered_bact_plus_fungi_df[\n",
    "            \"Mean Squared Error\"\n",
    "        ].sum()\n",
    "        custom_bact_fungi_std_mse = filtered_bact_plus_fungi_df[\n",
    "            \"Mean Squared Error\"\n",
    "        ].std()\n",
    "\n",
    "        bact_fungi_sum_mse = filtered_bact_fungi_combined_df[\n",
    "            \"Mean Squared Error\"\n",
    "        ].sum()\n",
    "        bact_fungi_std_mse = filtered_bact_fungi_combined_df[\n",
    "            \"Mean Squared Error\"\n",
    "        ].std()\n",
    "\n",
    "        test_error_df_list.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"# of Total Samples\": n_sample,\n",
    "                    \"Sum of Errors\": custom_bact_fungi_sum_mse,\n",
    "                    \"ymin\": custom_bact_fungi_sum_mse - custom_bact_fungi_std_mse,\n",
    "                    \"ymax\": custom_bact_fungi_sum_mse + custom_bact_fungi_std_mse,\n",
    "                    \"Dataset\": \"Bacteria_Fungi (Separated)\",\n",
    "                },\n",
    "                index=[0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        test_error_df_list.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"# of Total Samples\": n_sample,\n",
    "                    \"Sum of Errors\": bact_fungi_sum_mse,\n",
    "                    \"ymin\": bact_fungi_sum_mse - bact_fungi_std_mse,\n",
    "                    \"ymax\": bact_fungi_sum_mse + bact_fungi_std_mse,\n",
    "                    \"Dataset\": \"Bacteria_Fungi (Combined)\",\n",
    "                },\n",
    "                index=[0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    my_combined_results_df = pd.concat(test_error_df_list).reset_index()\n",
    "    my_combined_results_df[\"Dataset\"] = pd.Categorical(\n",
    "            my_combined_results_df[\"Dataset\"],\n",
    "            categories=[\"Bacteria_Fungi (Separated)\", \"Bacteria_Fungi (Combined)\"],\n",
    "            ordered=True,\n",
    "        )\n",
    "\n",
    "\n",
    "    # Create a line plot with ribbon variation using plotnine\n",
    "    gg = (\n",
    "        p9.ggplot(my_combined_results_df)\n",
    "        + p9.aes(\n",
    "            x=\"# of Total Samples\",\n",
    "            y=\"Sum of Errors\",\n",
    "            ymin=\"ymin\",\n",
    "            ymax=\"ymax\",\n",
    "            fill=\"Dataset\",\n",
    "        )  # Add fill argument\n",
    "        + p9.geom_line(p9.aes(color=\"Dataset\"))\n",
    "        + p9.geom_ribbon(alpha=0.3)\n",
    "        + p9.scale_color_manual(values=[\"red\", \"blue\"])\n",
    "        + p9.scale_fill_manual(values=[\"red\", \"blue\"])\n",
    "        + p9.scale_x_continuous(breaks=n_samples_list)\n",
    "        + p9.xlab(\"# of Total Samples\")\n",
    "        + p9.ggtitle(f\"{name}\")\n",
    "    )\n",
    "\n",
    "    print(gg)\n",
    "    if name is not None:\n",
    "        gg.save(f\"{name}.png\", dpi=1500)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NECROMASS DF\n",
    "# date_time = \"2023-07-20_16:44\"\n",
    "# date_time = \"2023-08-03_18:13\"\n",
    "date_time = \"2023-08-18_14:28\"\n",
    "date_time = \"2023-08-18_14:28\"\n",
    "date_time = \"2023-09-15_18:01\"\n",
    "date_time = \"2023-09-15_20:03\"\n",
    "\n",
    "error_df = pd.read_csv(f\"{root_results_dir}/{date_time}_results.csv\")\n",
    "\n",
    "bact_df = error_df[error_df[\"Dataset\"] == \"necromass_bacteria_species\"]\n",
    "necromass_bact_error_df = get_combined_error_df(bact_df)\n",
    "fungi_df = error_df[error_df[\"Dataset\"] == \"necromass_fungi_species\"]\n",
    "necromass_fungi_error_df = get_combined_error_df(fungi_df)\n",
    "necromass_bact_plus_fungi_error_df = pd.concat(\n",
    "    [necromass_bact_error_df, necromass_fungi_error_df]\n",
    ")\n",
    "\n",
    "\n",
    "bact_fungi_df = error_df[error_df[\"Dataset\"] == \"necromass_bacteria_fungi_species\"]\n",
    "necromass_bact_fungi_combined_error_df = get_combined_error_df(bact_fungi_df)\n",
    "\n",
    "necromass_bact_plus_fungi_error_df = necromass_bact_plus_fungi_error_df[necromass_bact_plus_fungi_error_df[\"# of Total Samples\"] <= 60]\n",
    "necromass_bact_fungi_combined_error_df = necromass_bact_fungi_combined_error_df[necromass_bact_fungi_combined_error_df[\"# of Total Samples\"] <= 60]\n",
    "\n",
    "\n",
    "plot_sum_of_errors(necromass_bact_plus_fungi_error_df, necromass_bact_fungi_combined_error_df, name=\"necromass_species_sum_of_errors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c51af742e141fb8ae370995bc6149e53fca1868e122616bc9da9e07ef681ffa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
